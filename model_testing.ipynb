{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset_train.csv'\n",
    "dataset_train = pd.read_csv(dataset_path)\n",
    "\n",
    "dataset_path = './dataset_test.csv'\n",
    "dataset_test = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['bed', 'bath', 'house_size']\n",
    "output_columns = ['price']\n",
    "\n",
    "all_columns = input_columns + output_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train = dataset_train[all_columns].dropna()\n",
    "training_data = np.array(cleaned_train, dtype=np.float32)\n",
    "x = cleaned_train[input_columns]\n",
    "x = np.array(x, dtype=np.float32)\n",
    "y = cleaned_train[output_columns]\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "cleaned_test = dataset_test[all_columns].dropna()\n",
    "x_test = cleaned_test[input_columns]\n",
    "x_test = np.array(x_test, dtype=np.float32)\n",
    "y_test = cleaned_test[output_columns]\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential( \n",
    "  [\n",
    "    layers.Input(3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1),\n",
    "  ] \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15278/15278 [==============================] - 59s 4ms/step - loss: 508611723264.0000 - mae: 201534.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[508611723264.0, 201534.671875]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548/2548 [==============================] - 7s 3ms/step - loss: 381720264704.0000 - mae: 200610.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[381720264704.0, 200610.3125]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the mean absolute error on training and testing data are simillar:\n",
    "- 201.534.6719 for training\n",
    "- 200.610.3125 for testing\n",
    "\n",
    "which means that no overfitting was present.\n",
    "\n",
    "Generally speaking, the error is quite high but obviously it is expected behaviour as the data comes from different regions across US and because the prices vary heavily, this relation is reflected by the model performance.\n",
    "\n",
    "Obviously, for final model, we should use data only from 1 region (Poland) and include additional data as city of the houshold, type of apartment (house or flat), distance from nearest cities, districts, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
